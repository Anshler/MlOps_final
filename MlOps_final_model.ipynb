{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import dependencies"
   ],
   "metadata": {
    "id": "IcY8q2dCUbo3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import mlflow.pytorch\n",
    "import torch.optim as optim\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from safetensors.torch import save_file"
   ],
   "metadata": {
    "id": "o2SzMYELTnm2",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:11:15.779388Z",
     "start_time": "2025-04-26T13:11:15.763753Z"
    }
   },
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create dataset"
   ],
   "metadata": {
    "id": "_qeP5yuKUfNW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = MinMaxScaler()\n",
    "X, y = make_classification(n_samples=100_000, n_features=20, n_informative=18, n_redundant=2, n_repeated=0, n_classes=2, random_state=42)\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)"
   ],
   "metadata": {
    "id": "u8OjsAxSTtDG",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:11:15.889717Z",
     "start_time": "2025-04-26T13:11:15.779388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model\n"
   ],
   "metadata": {
    "id": "eK-scfbsVlme"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_layer=64):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, hidden_layer)\n",
    "        self.fc2 = nn.Linear(hidden_layer, hidden_layer)\n",
    "        self.fc3 = nn.Linear(hidden_layer, hidden_layer)\n",
    "        self.fc4 = nn.Linear(hidden_layer, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x"
   ],
   "metadata": {
    "id": "dm552PjGVnIO",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:11:16.033741Z",
     "start_time": "2025-04-26T13:11:16.018015Z"
    }
   },
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "GRID_CONFIG = {\n",
    "  'hidden_layer': [64, 128, 512],\n",
    "  'learning_rate': [0.01, 0.005, 0.001],\n",
    "}\n",
    "\n",
    "EPOCH = 30"
   ],
   "metadata": {
    "id": "L4xsRZfiZXHg",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:11:16.159878Z",
     "start_time": "2025-04-26T13:11:16.144011Z"
    }
   },
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train & Test"
   ],
   "metadata": {
    "id": "0GIVZepPb6fW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for hidden_layer in GRID_CONFIG['hidden_layer']:\n",
    "  for lr in GRID_CONFIG['learning_rate']:\n",
    "    with mlflow.start_run():\n",
    "      # Create model\n",
    "      model = Model(hidden_layer=hidden_layer).to(device)\n",
    "\n",
    "      # Loss function and optimizer\n",
    "      criterion = nn.BCELoss()\n",
    "      optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "      # Train model\n",
    "      model.train()\n",
    "      for epoch in range(EPOCH):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train_tensor).squeeze()\n",
    "        loss = criterion(y_pred, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "      # Evaluate\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        y_pred_test = model(X_test_tensor).squeeze()\n",
    "        y_pred_test = (y_pred_test > 0.5).float()  # Convert sigmoid output to binary (0 or 1)\n",
    "\n",
    "      # Calculate accuracy\n",
    "      accuracy = accuracy_score(y_test_tensor.cpu(), y_pred_test.cpu())\n",
    "      print(f\"Hidden Layer: {hidden_layer:>4}   Learning Rate: {lr:<7} Accuracy: {accuracy:<5.4f}\")\n",
    "\n",
    "      # Log parameters\n",
    "      mlflow.log_param(\"hidden_layer\", hidden_layer)\n",
    "      mlflow.log_param(\"learning_rate\", lr)\n",
    "\n",
    "      # Log metric\n",
    "      mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "      # Log model\n",
    "      mlflow.pytorch.log_model(model, artifact_path=\"model\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9sZD01cY94f",
    "outputId": "f44516dc-9c16-42d0-b0ed-6ef9240ae817",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:12:36.810785Z",
     "start_time": "2025-04-26T13:12:01.715484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:02 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:   64   Learning Rate: 0.01    Accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:   64   Learning Rate: 0.005   Accuracy: 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:08 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:09 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:   64   Learning Rate: 0.001   Accuracy: 0.7412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  128   Learning Rate: 0.01    Accuracy: 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:16 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  128   Learning Rate: 0.005   Accuracy: 0.8142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:19 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:20 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  128   Learning Rate: 0.001   Accuracy: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:24 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  512   Learning Rate: 0.01    Accuracy: 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:27 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  512   Learning Rate: 0.005   Accuracy: 0.7715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/04/26 20:12:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer:  512   Learning Rate: 0.001   Accuracy: 0.8457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/26 20:12:36 WARNING mlflow.utils.requirements_utils: Found torch version (2.6.0+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torch==2.6.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/04/26 20:12:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": "# Save best run to registry",
   "metadata": {
    "id": "O5Kxw9bPb_ko"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "experiment_name = \"Default\"\n",
    "MODEL_NAME = \"bestModel\"\n",
    "metric_name = \"accuracy\"\n",
    "model_subpath = \"model\"\n",
    "\n",
    "client = MlflowClient()"
   ],
   "metadata": {
    "id": "xW6pX4_BTjjW",
    "ExecuteTime": {
     "end_time": "2025-04-26T13:12:51.302487Z",
     "start_time": "2025-04-26T13:12:51.286765Z"
    }
   },
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T13:12:52.288681Z",
     "start_time": "2025-04-26T13:12:52.256934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get experiment by name\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "  raise ValueError(f\"Experiment '{experiment_name}' not found.\")\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Search runs, sorted by metric descending\n",
    "runs = client.search_runs(\n",
    "  experiment_ids=[experiment_id],\n",
    "  order_by=[f\"metrics.{metric_name} DESC\"],\n",
    "  max_results=1\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "  raise ValueError(f\"No runs found in experiment '{experiment_name}'.\")\n",
    "\n",
    "# Best run\n",
    "best_run = runs[0]\n",
    "run_id = best_run.info.run_id\n",
    "best_metric = best_run.data.metrics.get(metric_name)\n",
    "params = best_run.data.params\n",
    "\n",
    "print(f\"Best run ID: {run_id} with {metric_name}: {best_metric}\")\n",
    "print(f\"Best run params: {params}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: 3620c7fec6fd41cda740da97cc8f0c8c with accuracy: 0.8456666666666667\n",
      "Best run params: {'hidden_layer': '512', 'learning_rate': '0.001'}\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T13:12:57.815213Z",
     "start_time": "2025-04-26T13:12:57.775536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "  production_model_version = client.get_latest_versions(MODEL_NAME, stages=[\"Production\"])[0]\n",
    "  production_model_version = production_model_version.version\n",
    "  print(f\"Current production model version: {production_model_version}\")\n",
    "\n",
    "  # Get the production model's accuracy (or other metric)\n",
    "  current_prod_run_id = client.get_model_version(MODEL_NAME, production_model_version).run_id\n",
    "  current_prod_run = client.get_run(current_prod_run_id)\n",
    "  current_prod_accuracy = current_prod_run.data.metrics.get(metric_name)\n",
    "\n",
    "  print(f\"Current production model {metric_name}: {current_prod_accuracy}\")\n",
    "\n",
    "  # Compare and promote if the new model is better\n",
    "  if best_metric > current_prod_accuracy:\n",
    "    print(f\"\\nNew model is better, promoting to production.\\n\")\n",
    "    # New production model version\n",
    "    new_model_version = client.create_model_version(\n",
    "      name=MODEL_NAME,\n",
    "      source=f\"runs:/{run_id}/{model_subpath}\",\n",
    "      run_id=run_id,\n",
    "    ).version\n",
    "\n",
    "    # Archive the current production model\n",
    "    client.transition_model_version_stage(\n",
    "      name=MODEL_NAME,\n",
    "      version=production_model_version,\n",
    "      stage=\"Archived\"\n",
    "    )\n",
    "    # Promote new model to production\n",
    "    client.transition_model_version_stage(\n",
    "      name=MODEL_NAME,\n",
    "      version=new_model_version,\n",
    "      stage=\"Production\"\n",
    "    )\n",
    "\n",
    "    print(f\"New production model version: {new_model_version}\")\n",
    "    print(f\"New production model {metric_name}: {best_metric}\")\n",
    "  else:\n",
    "    print(f\"\\nCurrent production model is the best. Keeping the same.\\n\")\n",
    "except:\n",
    "  # If no production model exists, we can directly set the new model as production\n",
    "  print(f\"No production model exists, setting the new best model as production.\")\n",
    "  client.create_registered_model(MODEL_NAME)\n",
    "  new_model_version = client.create_model_version(\n",
    "    name=MODEL_NAME,\n",
    "    source=f\"runs:/{run_id}/{model_subpath}\",\n",
    "    run_id=run_id\n",
    "  ).version\n",
    "\n",
    "  client.transition_model_version_stage(\n",
    "    name=MODEL_NAME,\n",
    "    version=new_model_version,\n",
    "    stage=\"Production\"\n",
    "  )\n",
    "\n",
    "  print(f\"New production model version: {new_model_version}\")\n",
    "  print(f\"New production model {metric_name}: {best_metric}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No production model exists, setting the new best model as production.\n",
      "New production model version: 1\n",
      "New production model accuracy: 0.8456666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4424\\4117178713.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  production_model_version = client.get_latest_versions(MODEL_NAME, stages=[\"Production\"])[0]\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4424\\4117178713.py:50: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save best model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T13:13:20.476234Z",
     "start_time": "2025-04-26T13:13:20.431352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the latest production model version\n",
    "production_model_versions = client.get_latest_versions(MODEL_NAME, stages=[\"Production\"])\n",
    "\n",
    "if production_model_versions:\n",
    "  # Get the most recent production version (latest version with stage 'Production')\n",
    "  latest_production_version = production_model_versions[0].version\n",
    "  print(f\"Latest production model version: {latest_production_version}\")\n",
    "\n",
    "  # Load the model from the model registry\n",
    "  model_subpath = \"model\"\n",
    "  model_uri = f\"models:/{MODEL_NAME}/{latest_production_version}\"\n",
    "  model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "  save_file(model.state_dict(), \"local_prod_backup.safetensors\")\n",
    "  torch.save({\n",
    "    'X_test': X_test_tensor,\n",
    "    'y_test': y_test_tensor,\n",
    "    }, \"test_data.pt\")\n",
    "\n",
    "  print(f\"Model saved successfully\")\n",
    "else:\n",
    "  print(f\"No production model found for {MODEL_NAME}.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest production model version: 1\n",
      "Model saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4424\\1076112338.py:2: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  production_model_versions = client.get_latest_versions(MODEL_NAME, stages=[\"Production\"])\n"
     ]
    }
   ],
   "execution_count": 79
  }
 ]
}
